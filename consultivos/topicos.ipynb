{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from plotly import tools\n",
    "import pandas as pd\n",
    "import plotly.offline as pyo\n",
    "import plotly.graph_objs as go\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "import spacy\n",
    "\n",
    "from helpers import MiCorpus\n",
    "import helpers as hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('es_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_models(corpus, topics, params, ngrams, directory, lang, other=None):\n",
    "    \"\"\"\n",
    "    Crea modelos LDA para diferentes números de tópicos\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    corpus: MiCorpus\n",
    "    topics: iterable con el # de tópicos\n",
    "    params: dict con parámetros requeridos en modelo\n",
    "    ngrams: dict (bigrams, trigrams)\n",
    "    directory: str   \n",
    "    lang: spacy.lang\n",
    "    other: dict, optional (stopwords, postags, entities, stemmer)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict of str\n",
    "        Dict con resultados de modelos LDA\n",
    "    \"\"\"\n",
    "    models = {}\n",
    "    \n",
    "    for i in topics:\n",
    "        result = {}\n",
    "        id2word = corpus.diccionario\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter('ignore')\n",
    "            lda = LdaModel(corpus, num_topics=i, id2word=id2word, **params)\n",
    "        \n",
    "        texts = list(hp.iter_documents(ngrams, directory, lang, other))\n",
    "        cm = CoherenceModel(model=lda, texts=texts, dictionary=id2word, coherence='c_v')\n",
    "        coherence = cm.get_coherence()\n",
    "        \n",
    "        result['lda'] = lda\n",
    "        result['coherence'] = coherence\n",
    "        \n",
    "        models[i] = result\n",
    "    \n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dircorpus = '/Users/tombito/Dropbox/datasets/banrep/consultivos/corpus'\n",
    "pathstops = '/Users/tombito/Dropbox/datasets/wordlists/stopwords/stopwords.xlsx'\n",
    "dirmodels = 'modelos'\n",
    "os.makedirs(dirmodels, exist_ok=True)\n",
    "\n",
    "stops = hp.load_stopwords(pathstops, 'spanish', col='word')\n",
    "tags = ['NOUN', 'VERB', 'ADJ', 'ADV', 'ADP','AUX', 'DET', 'PRON']\n",
    "ents = ['PER', 'ORG']\n",
    "\n",
    "extra = dict(stopwords=stops, postags=tags, entities=ents, ) \n",
    "# opcional stemmer=SnowballStemmer('spanish')\n",
    "# habiendo importado from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "consultivos = MiCorpus(dircorpus, nlp, extra)\n",
    "diccionario = consultivos.diccionario\n",
    "diccionario.save(os.path.join(dirmodels, 'consultivos.dict'))\n",
    "\n",
    "ngramas = consultivos.ngramas\n",
    "bigramas = ngramas['bigrams']\n",
    "bigramas.save(os.path.join(dirmodels, 'bigramas'))\n",
    "trigramas = ngramas['trigrams']\n",
    "trigramas.save(os.path.join(dirmodels, 'trigramas'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 30min 6s, sys: 5min 47s, total: 35min 54s\n",
      "Wall time: 19min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n = (5, 10, 20, 35, 55, 80, 110)\n",
    "lda_params = dict(chunksize=100, passes=2, alpha='auto', eta='auto', random_state=100)\n",
    "modelos = create_models(consultivos, n, lda_params, ngramas, dircorpus, nlp, extra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = [modelos[i]['coherence'] for i in n]\n",
    "\n",
    "# if several indexes with max score, choose first\n",
    "best_is = [i for i, j in enumerate(scores) if j == max(scores)][0]\n",
    "best = n[best_is]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generar gráfica del Coherence Score\n",
    "colors = ['rgba(204,204,204,1)' if not i==best else 'rgba(222,45,38,0.8)' for i in n]\n",
    "\n",
    "trace = go.Bar(x=n, y=scores, marker=dict(color=colors))\n",
    "layout = dict(title='Coherence Score para cada número de tópicos', \n",
    "              xaxis=dict(title='Número de tópicos'), \n",
    "              yaxis=dict(title='Coherence Score (c_v)',\n",
    "                         hoverformat='.3f')\n",
    "             )\n",
    "\n",
    "fig = dict(data=[trace], layout=layout)\n",
    "filename = os.path.join(dirmodels, 'coherence.html')\n",
    "cohfile = pyo.plot(fig, show_link=False, filename=filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# para guardar otro habría que seleccionar otro n\n",
    "ldamodel = modelos[best]['lda']\n",
    "ldamodel.save(os.path.join(dirmodels, 'topicos-{:0>2}.lda'.format(best)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=(dict(d) for d in ldamodel[consultivos]), index=hp.get_docnames(dircorpus))\n",
    "df['dominante'] = df.idxmax(axis=1)\n",
    "df.to_csv(os.path.join(dirmodels, 'doctopics-{:0>2}.csv'.format(best)), encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "    vis = pyLDAvis.gensim.prepare(ldamodel, list(consultivos), diccionario, sort_topics=False)\n",
    "\n",
    "pyLDAvis.save_html(vis, os.path.join(dirmodels, 'topicos-{:0>2}.html'.format(best)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47    0.1507\n",
       "55    0.0822\n",
       "84    0.0685\n",
       "75    0.0685\n",
       "93    0.0685\n",
       "53    0.0411\n",
       "Name: dominante, dtype: float64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of Documents for Each Topic\n",
    "rows = 3\n",
    "cols = 2\n",
    "\n",
    "topic_counts = df['dominante'].value_counts()\n",
    "topic_contribution = round(topic_counts/topic_counts.sum(), 4)\n",
    "head_topics = topic_contribution.head(rows*cols)\n",
    "head_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = tools.make_subplots(rows=rows, cols=cols, \n",
    "                          subplot_titles=(['Tópico {}'.format(t) for t in head_topics.index]),\n",
    "                          print_grid=False,\n",
    "                         )\n",
    "\n",
    "r = 1\n",
    "for i, t in enumerate(head_topics.index, 1):\n",
    "    dfg=pd.DataFrame(ldamodel.show_topic(t, 15), columns=['term','prob']).set_index('term')\n",
    "    \n",
    "    trace = go.Bar(x=dfg['prob'], y=dfg.index, orientation='h',)\n",
    "    \n",
    "    if i%2==0:\n",
    "        fig.add_trace(trace, row=r, col=2)\n",
    "        r+=1\n",
    "    else:\n",
    "        fig.add_trace(trace, row=r, col=1)\n",
    "\n",
    "fig.layout.update(title='Principales palabras de tópicos más dominantes',\n",
    "                  showlegend=False, yaxis=dict(automargin=True),\n",
    "                  height=1200, width=1200)\n",
    "\n",
    "f = os.path.join(dirmodels, 'word_topics-{:0>2}.html'.format(best))\n",
    "headfile = pyo.plot(fig, show_link=False, filename=f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
